{"cells":[{"outputs":[{"output_type":"stream","text":"Looking in indexes: https://pypi.douban.com/simple\nRequirement already satisfied: opencv-python in /opt/conda/lib/python3.8/site-packages (4.4.0.44)\nRequirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.8/site-packages (from opencv-python) (1.19.1)\nLooking in indexes: https://pypi.douban.com/simple\nRequirement already satisfied: pillow in /opt/conda/lib/python3.8/site-packages (7.2.0)\nRequirement already up-to-date: tqdm in /opt/conda/lib/python3.8/site-packages (4.50.2)\nRequirement already satisfied: efficientnet in /opt/conda/lib/python3.8/site-packages (1.1.1)\nRequirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in /opt/conda/lib/python3.8/site-packages (from efficientnet) (1.0.8)\nRequirement already satisfied: scikit-image in /opt/conda/lib/python3.8/site-packages (from efficientnet) (0.17.2)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.8/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (2.10.0)\nRequirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.8/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.19.1)\nRequirement already satisfied: scipy>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from scikit-image->efficientnet) (1.5.2)\nRequirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-image->efficientnet) (3.2.2)\nRequirement already satisfied: networkx>=2.0 in /opt/conda/lib/python3.8/site-packages (from scikit-image->efficientnet) (2.4)\nRequirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /opt/conda/lib/python3.8/site-packages (from scikit-image->efficientnet) (7.2.0)\nRequirement already satisfied: imageio>=2.3.0 in /opt/conda/lib/python3.8/site-packages (from scikit-image->efficientnet) (2.9.0)\nRequirement already satisfied: tifffile>=2019.7.26 in /opt/conda/lib/python3.8/site-packages (from scikit-image->efficientnet) (2020.8.13)\nRequirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.8/site-packages (from scikit-image->efficientnet) (1.1.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.15.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (0.10.0)\nRequirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (2.8.1)\nRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (2.4.7)\nRequirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.8/site-packages (from networkx>=2.0->scikit-image->efficientnet) (4.4.2)\nNum GPUs Available:  1\nDevice mapping:\n/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla T4, pci bus id: 0000:00:07.0, compute capability: 7.5\n\n<tensorflow.python.client.session.Session object at 0x7fc8a01a5670>\n","name":"stdout"}],"execution_count":2,"source":"!pip install opencv-python -i https://pypi.douban.com/simple\n!pip install pillow -i https://pypi.douban.com/simple\n!pip install --upgrade tqdm\n!pip install efficientnet\n\nimport pickle\nimport glob\nfrom multiprocessing import Pool\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split \nimport concurrent.futures\nfrom PIL import Image\nfrom skimage import io\nimport tensorflow as tf\n\nimport cv2\nimport pandas as pd\nimport os\nfrom tqdm import tqdm\nimport time\nimport json\nimport numpy as np\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\nfrom tensorflow.keras.layers import Conv2D,GlobalAveragePooling2D,Convolution2D,BatchNormalization, Activation,MaxPooling2D, MaxPool2D, Dropout, Flatten, Dense\nfrom tensorflow.keras.datasets import mnist\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau,EarlyStopping,ModelCheckpoint\nfrom tensorflow import keras\nimport efficientnet.tfkeras as efn\nfrom keras.applications.resnet50 import ResNet50\nfrom keras.applications import InceptionV3,MobileNetV2,InceptionResNetV2\nfrom keras.applications.resnet import ResNet101\nimport tensorflow.keras.backend as K\ntf.compat.v1.disable_eager_execution()\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\ntf.config.experimental.list_physical_devices('GPU')\nprint(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n# sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))\nconfig = tf.compat.v1.ConfigProto(log_device_placement=True)\nconfig.gpu_options.allow_growth = True\nsess = tf.compat.v1.Session(config = config)\nprint(sess)","cell_type":"code","metadata":{"trusted":true,"collapsed":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"38C9717C7D1441BB80F210CEB57FC6ED","scrolled":false}},{"metadata":{"id":"187864F967AA46E88F1B0974E6FE19AE","notebookId":"5f8a59a1bfe3ac0015e8dfb2","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"def Model():\n    covn_base = InceptionV3(input_shape=(224,224,3),include_top=False,\n                            pooling='max',\n                            weights='imagenet'\n                            )\n#     covn_base.trainable = True\n    model = keras.Sequential()\n    model.add(covn_base)\n    model.add(keras.layers.Dense(3,activation='softmax'))\n    adam=tf.keras.optimizers.Adam(lr=3e-4,\n            # beta_1=0.9, \n            # beta_2=0.999,\n            # epsilon=None,\n            # decay=0.0, \n            # amsgrad=False\n            )\n    model.compile(optimizer=adam,\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n              metrics=['accuracy'],\n              )\n    return model","execution_count":14},{"metadata":{"id":"743AAE1DA56F48FA82559FD6F2D19B75","notebookId":"5f8a59a1bfe3ac0015e8dfb2","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"from tensorflow.keras import *\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.callbacks import LearningRateScheduler\ndef scheduler(epoch):\n    # 每隔100个epoch，学习率减小为原来的1/10\n    if epoch % 100 == 0 and epoch != 0:\n        lr = K.get_value(model.optimizer.lr)\n        K.set_value(model.optimizer.lr, lr * 0.1)\n        print(\"lr changed to {}\".format(lr * 0.1))\n    return K.get_value(model.optimizer.lr)\n \n# reduce_lr = LearningRateScheduler(scheduler)","execution_count":3},{"metadata":{"id":"78CA7BFD18024F24BF589FB4C1412AC4","notebookId":"5f8a59a1bfe3ac0015e8dfb2","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":true},"cell_type":"code","outputs":[{"output_type":"stream","text":"Found 141669 images belonging to 3 classes.\nFound 35416 images belonging to 3 classes.\nEpoch 1/10\n2213/2213 [==============================] - 2119s 957ms/step - batch: 1106.0000 - size: 63.9878 - loss: 0.5817 - accuracy: 0.7663 - val_loss: 0.5931 - val_accuracy: 0.7751\nEpoch 2/10\n2213/2213 [==============================] - 1416s 640ms/step - batch: 1106.0000 - size: 63.9878 - loss: 0.5138 - accuracy: 0.7931 - val_loss: 0.5528 - val_accuracy: 0.7651\nEpoch 3/10\n2213/2213 [==============================] - ETA: 0s - batch: 1106.0000 - size: 63.9878 - loss: 0.4832 - accuracy: 0.8037\nEpoch 00003: ReduceLROnPlateau reducing learning rate to 6.000000284984708e-05.\n2213/2213 [==============================] - 1437s 649ms/step - batch: 1106.0000 - size: 63.9878 - loss: 0.4832 - accuracy: 0.8037 - val_loss: 1.0446 - val_accuracy: 0.6461\nEpoch 4/10\n2213/2213 [==============================] - 1417s 640ms/step - batch: 1106.0000 - size: 63.9878 - loss: 0.3849 - accuracy: 0.8423 - val_loss: 0.4360 - val_accuracy: 0.8168\nEpoch 5/10\n2213/2213 [==============================] - 1414s 639ms/step - batch: 1106.0000 - size: 63.9878 - loss: 0.3181 - accuracy: 0.8689 - val_loss: 0.4678 - val_accuracy: 0.8118\nEpoch 6/10\n2213/2213 [==============================] - ETA: 0s - batch: 1106.0000 - size: 63.9878 - loss: 0.2354 - accuracy: 0.9026\nEpoch 00006: ReduceLROnPlateau reducing learning rate to 1.2000000424450263e-05.\n2213/2213 [==============================] - 1415s 639ms/step - batch: 1106.0000 - size: 63.9878 - loss: 0.2354 - accuracy: 0.9026 - val_loss: 0.5511 - val_accuracy: 0.7960\nEpoch 7/10\n2213/2213 [==============================] - 1416s 640ms/step - batch: 1106.0000 - size: 63.9878 - loss: 0.1081 - accuracy: 0.9556 - val_loss: 0.8298 - val_accuracy: 0.7944\nEpoch 8/10\n 566/2213 [======>.......................] - ETA: 15:13 - batch: 282.5000 - size: 64.0000 - loss: 0.0674 - accuracy: 0.9722","name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-00869795b5dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m model.fit(\n\u001b[0m\u001b[1;32m     89\u001b[0m     \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mBatch_s\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/engine/training_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_select_training_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m     return func.fit(\n\u001b[0m\u001b[1;32m    791\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    572\u001b[0m     training_utils.check_generator_arguments(\n\u001b[1;32m    573\u001b[0m         y, sample_weight, validation_split=validation_split)\n\u001b[0;32m--> 574\u001b[0;31m     return fit_generator(\n\u001b[0m\u001b[1;32m    575\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/engine/training_v1.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1087\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_sample_weight_modes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1089\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3822\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_arrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_symbols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3824\u001b[0;31m     fetched = self._callable_fn(*array_vals,\n\u001b[0m\u001b[1;32m   3825\u001b[0m                                 run_metadata=self.run_metadata)\n\u001b[1;32m   3826\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1468\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1469\u001b[0m         \u001b[0mrun_metadata_ptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_NewBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1470\u001b[0;31m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0m\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1472\u001b[0m                                                run_metadata_ptr)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":"import numpy as np\n\nBatch_s=64\n# # 训练集0.8\n# train_data = tf.keras.preprocessing.image_dataset_from_directory(\n#     '/home/kesci/work/picture_data',\n#     validation_split = 0.2,\n#     subset='training',\n#     seed=3090,\n#     image_size=(224,224),\n#     batch_size=Batch_s\n# )\n# # 验证集0.2\n# val_data = tf.keras.preprocessing.image_dataset_from_directory(\n#     '/home/kesci/work/picture_data',\n#     validation_split = 0.2,\n#     subset='validation',\n#     seed=3090,\n#     image_size=(224,224),\n#     batch_size=Batch_s\n# )\ndef random_crop_image(image):\n      height, width = image.shape[:2]\n    #   random_array = np.random.uniform(0.6,0.7)\n      random_array=0.7\n      y = int(random_array*height)\n      image_crop = image[0:y,0:width,0:3]\n      image_crop = cv2.resize(image_crop,(224, 224))\n      return image_crop\n    \ntrain_datagen = ImageDataGenerator(rescale=1./255,\n    # shear_range=0.2,\n    # zoom_range=0.2,\n    # horizontal_flip=True,\n    # brightness_range=[0.1,0.3],\n    # preprocessing_function=random_crop_image,\n    validation_split=0.2)\n\n\ntest_datagen = ImageDataGenerator(rescale=1./255,\n    # shear_range=0.2,\n    # zoom_range=0.2,\n    # horizontal_flip=True,\n    # brightness_range=[0.1,0.3],\n    # preprocessing_function=random_crop_image,\n    validation_split=0.2)\n\n# 训练集0.8\ntrain_data = train_datagen.flow_from_directory(\n    '/home/kesci/work/picture_data',\n    subset='training',\n    class_mode='sparse',\n    # seed=3090,\n    target_size=(224,224),\n    batch_size=Batch_s)\n\n# 验证集0.2\nval_data = test_datagen.flow_from_directory(\n    '/home/kesci/work/picture_data',\n    class_mode='sparse',\n    subset='validation',\n    # seed=3090,\n    target_size=(224,224),\n    batch_size=Batch_s)\n\nEarlyStop=EarlyStopping(monitor='val_accuracy',\n                        patience=8,verbose=1, mode='max')\n#减小学习率\nReduce=ReduceLROnPlateau(monitor='val_accuracy',\n                         factor=0.2,\n                         patience=2,\n                         verbose=1,\n                         mode='max',\n                        #  min_delta=0.0001,\n                         cooldown=0,\n                         min_lr=0\n                         )\n                                                \ncheckpoint = ModelCheckpoint(f'/home/kesci/work/cnn_model/inceptionnet.h5',\n                            monitor='val_accuracy',\n                            verbose=0,\n                            mode='max',\n                            save_best_only=True)\n# NUM_TRAIN=141668\n# NUM_TEST=35417\nmodel=Model()\n\nmodel.fit(\n    train_data,\n    steps_per_epoch=train_data.samples//Batch_s,\n    epochs=10,\n    callbacks=[Reduce,checkpoint],\n    validation_data=val_data,\n    validation_steps=val_data.samples//Batch_s\n    )\n","execution_count":17},{"metadata":{"id":"937E9930EC1944A7828B2AAE271FB20E","notebookId":"5f8a59a1bfe3ac0015e8dfb2","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"Found 72778 images belonging to 1 classes.\n","name":"stdout"}],"source":"# 测试集预测\ntest_datagen = ImageDataGenerator(\n    rescale=1./255,\n    )\ntest_generator = test_datagen.flow_from_directory(\n    '/home/kesci/work/test_data', \n    target_size=(224, 224),\n    batch_size=64,\n    class_mode='sparse', \n    shuffle=False,)\ntest_generator.reset()\n","execution_count":3},{"metadata":{"id":"EE0CB983C2B14496AAAC9113733E287D","notebookId":"5f8a59a1bfe3ac0015e8dfb2","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"model = tf.keras.models.load_model('/home/kesci/work/cnn_model/inceptionnet.h5')","execution_count":4},{"metadata":{"id":"504146DDE1B94CDC8D9942848ECAC7D1","notebookId":"5f8a59a1bfe3ac0015e8dfb2","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"WARNING:tensorflow:From /opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/engine/training_v1.py:2070: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\nInstructions for updating:\nThis property should not be used in TensorFlow 2.0, as updates are applied automatically.\n","name":"stdout"}],"source":"pred = model.predict(test_generator, verbose=1)","execution_count":5},{"metadata":{"id":"25EEA648006E4E968E41997E727143F5","notebookId":"5f8a59a1bfe3ac0015e8dfb2","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"array([[0.5264642 , 0.07702505, 0.39651078],\n       [0.00889829, 0.04002218, 0.95107955],\n       [0.17420694, 0.08438879, 0.74140424],\n       ...,\n       [0.37153983, 0.37002924, 0.25843093],\n       [0.65803283, 0.31800178, 0.02396537],\n       [0.06305029, 0.9315972 , 0.00535253]], dtype=float32)"},"transient":{},"execution_count":26}],"source":"pred","execution_count":26},{"metadata":{"id":"19CD728F0E60444CA2D05632ED05480C","notebookId":"5f8a59a1bfe3ac0015e8dfb2","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":true},"cell_type":"code","outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"['100017842.jpg',\n '100057293.jpg',\n '1000599894.jpg',\n '1000600110.jpg',\n '1000974891.jpg',\n '1001038363.jpg',\n '1001445041.jpg',\n '1001679799.jpg',\n '100169257.jpg',\n '1001851110.jpg',\n '1004326025.jpg',\n '1005046809.jpg',\n '1005053527.jpg',\n '1005393572.jpg',\n '100586098.jpg',\n '100589879.jpg',\n '1006700844.jpg',\n '100764988.jpg',\n '1008195763.jpg',\n '1008680896.jpg',\n '1009048204.jpg',\n '1009899643.jpg',\n '1010499194.jpg',\n '1011068897.jpg',\n '101108546.jpg',\n '1011126301.jpg',\n '101114208.jpg',\n '101150448.jpg',\n '101166462.jpg',\n '101166704.jpg',\n '101188799.jpg',\n '101375297.jpg',\n '101375898.jpg',\n '1013837646.jpg',\n '1015055767.jpg',\n '101555307.jpg',\n '1015921918.jpg',\n '10161846.jpg',\n '101810058.jpg',\n '1018895399.jpg',\n '1020097694.jpg',\n '1020686893.jpg',\n '1020736703.jpg',\n '1020984282.jpg',\n '1021245884.jpg',\n '1021474962.jpg',\n '1021507836.jpg',\n '1021540518.jpg',\n '1021575808.jpg',\n '102244559.jpg',\n '102568811.jpg',\n '1026095959.jpg',\n '1026346721.jpg',\n '102642691.jpg',\n '1026955704.jpg',\n '1027296417.jpg',\n '102737763.jpg',\n '102738402.jpg',\n '1027626675.jpg',\n '10281712.jpg',\n '102901741.jpg',\n '102901802.jpg',\n '1029356694.jpg',\n '1030047547.jpg',\n '103016080.jpg',\n '1030322993.jpg',\n '1030323229.jpg',\n '1030324779.jpg',\n '1030351878.jpg',\n '1030386173.jpg',\n '1030386249.jpg',\n '1030387347.jpg',\n '1030436221.jpg',\n '1030861730.jpg',\n '1030862032.jpg',\n '1030862158.jpg',\n '1031176292.jpg',\n '1031237664.jpg',\n '1031485751.jpg',\n '1031617241.jpg',\n '103220288.jpg',\n '10341007.jpg',\n '103436516.jpg',\n '103437470.jpg',\n '103515301.jpg',\n '1038278278.jpg',\n '1038379442.jpg',\n '1038782077.jpg',\n '1039575732.jpg',\n '103969044.jpg',\n '10416398.jpg',\n '10416399.jpg',\n '104191159.jpg',\n '104191658.jpg',\n '104336107.jpg',\n '10441367.jpg',\n '10441428.jpg',\n '10441514.jpg',\n '104419099.jpg',\n '1044201073.jpg',\n '1044509275.jpg',\n '104795157.jpg',\n '1049254660.jpg',\n '1051493357.jpg',\n '1051498473.jpg',\n '1052022664.jpg',\n '105209563.jpg',\n '1053289921.jpg',\n '10533194.jpg',\n '105348605.jpg',\n '1053603627.jpg',\n '1054058926.jpg',\n '1054313964.jpg',\n '105650117.jpg',\n '1058635407.jpg',\n '1058687048.jpg',\n '1059508472.jpg',\n '1059510158.jpg',\n '1059716790.jpg',\n '106037757.jpg',\n '106071959.jpg',\n '106072502.jpg',\n '106297182.jpg',\n '1063465451.jpg',\n '1063988293.jpg',\n '1064526300.jpg',\n '1064611247.jpg',\n '106473215.jpg',\n '1065639620.jpg',\n '1066370799.jpg',\n '106785324.jpg',\n '106806597.jpg',\n '1068471038.jpg',\n '1068592978.jpg',\n '1068594746.jpg',\n '106945151.jpg',\n '10722567.jpg',\n '10730097.jpg',\n '107329190.jpg',\n '1073944108.jpg',\n '1073984614.jpg',\n '10740596.jpg',\n '1074124832.jpg',\n '107981208.jpg',\n '107981556.jpg',\n '1079883021.jpg',\n '108293214.jpg',\n '10838466.jpg',\n '108405732.jpg',\n '108405736.jpg',\n '1084543725.jpg',\n '1085553333.jpg',\n '108635589.jpg',\n '1086954956.jpg',\n '108874903.jpg',\n '1089122671.jpg',\n '1090641575.jpg',\n '1090757755.jpg',\n '1090758193.jpg',\n '1090759873.jpg',\n '1090760893.jpg',\n '1090762153.jpg',\n '1090763387.jpg',\n '1091581435.jpg',\n '1091617390.jpg',\n '1091620670.jpg',\n '1091626782.jpg',\n '1091637125.jpg',\n '1091665009.jpg',\n '1091667309.jpg',\n '1091717691.jpg',\n '1091734627.jpg',\n '1091978689.jpg',\n '1091993759.jpg',\n '1092003295.jpg',\n '1092013665.jpg',\n '1092022567.jpg',\n '1092026071.jpg',\n '1092031695.jpg',\n '1092050825.jpg',\n '1092141709.jpg',\n '1092202789.jpg',\n '1092447237.jpg',\n '1092465530.jpg',\n '1092523730.jpg',\n '1092577788.jpg',\n '1092860776.jpg',\n '1093028145.jpg',\n '109309060.jpg',\n '109330432.jpg',\n '1093309130.jpg',\n '1093894824.jpg',\n '1093922916.jpg',\n '1094640997.jpg',\n '1094877937.jpg',\n '1094880135.jpg',\n '1094947913.jpg',\n '1094988967.jpg',\n '1095447011.jpg',\n '1095458071.jpg',\n '1095739604.jpg',\n '1095766861.jpg',\n '1095769922.jpg',\n '1095775026.jpg',\n '1095842862.jpg',\n '1095949519.jpg',\n '1096098677.jpg',\n '1096151236.jpg',\n '1096313632.jpg',\n '1096564003.jpg',\n '109663669.jpg',\n '109663671.jpg',\n '1096751350.jpg',\n '1096791354.jpg',\n '1097361344.jpg',\n '1097394134.jpg',\n '1097407164.jpg',\n '1097534091.jpg',\n '1097583074.jpg',\n '1097605833.jpg',\n '1097689987.jpg',\n '1097744941.jpg',\n '109801760.jpg',\n '109817935.jpg',\n '109823321.jpg',\n '109823616.jpg',\n '109823801.jpg',\n '1098521160.jpg',\n '1098619463.jpg',\n '1098630780.jpg',\n '10990763.jpg',\n '109909669.jpg',\n '10992409.jpg',\n '110024281.jpg',\n '110024618.jpg',\n '110024795.jpg',\n '110037824.jpg',\n '110037953.jpg',\n '110038124.jpg',\n '110127160.jpg',\n '110127162.jpg',\n '110132238.jpg',\n '110151098.jpg',\n '1101858730.jpg',\n '110201765.jpg',\n '110219589.jpg',\n '1102452009.jpg',\n '1102959665.jpg',\n '1103808394.jpg',\n '110414780.jpg',\n '1104891077.jpg',\n '110586211.jpg',\n '110587538.jpg',\n '110589031.jpg',\n '110590177.jpg',\n '110648359.jpg',\n '110648361.jpg',\n '11072473.jpg',\n '11072500.jpg',\n '1107744184.jpg',\n '1108029027.jpg',\n '1108379892.jpg',\n '1109937620.jpg',\n '111066459.jpg',\n '1110701117.jpg',\n '111125061.jpg',\n '111304602.jpg',\n '1113075246.jpg',\n '1113827889.jpg',\n '1113866531.jpg',\n '1113896521.jpg',\n '111396660.jpg',\n '111412551.jpg',\n '1114230697.jpg',\n '1114714090.jpg',\n '1114715684.jpg',\n '1114722086.jpg',\n '111500729.jpg',\n '1115444203.jpg',\n '111601671.jpg',\n '1116114065.jpg',\n '111616902.jpg',\n '111620387.jpg',\n '1116382289.jpg',\n '1116389697.jpg',\n '1116399313.jpg',\n '11164432.jpg',\n '11164447.jpg',\n '1116534293.jpg',\n '1116535871.jpg',\n '1116536723.jpg',\n '1116538579.jpg',\n '1116539191.jpg',\n '1116541709.jpg',\n '1116544401.jpg',\n '1116550103.jpg',\n '1116550951.jpg',\n '1116554161.jpg',\n '1116560861.jpg',\n '1116562075.jpg',\n '1116563775.jpg',\n '1116566543.jpg',\n '1116580901.jpg',\n '1116640331.jpg',\n '1116658175.jpg',\n '1116672677.jpg',\n '1116699337.jpg',\n '1116705325.jpg',\n '1116712951.jpg',\n '1116797754.jpg',\n '1116809356.jpg',\n '1116888992.jpg',\n '1116914333.jpg',\n '1117044041.jpg',\n '1117147975.jpg',\n '1117233168.jpg',\n '1117247908.jpg',\n '1117273361.jpg',\n '1117371918.jpg',\n '1117373404.jpg',\n '1117373646.jpg',\n '1117374736.jpg',\n '1117376004.jpg',\n '1117381698.jpg',\n '1117388488.jpg',\n '1117389212.jpg',\n '1117391818.jpg',\n '1117394508.jpg',\n '1117396510.jpg',\n '1117398188.jpg',\n '1117405362.jpg',\n '1117453840.jpg',\n '1117510464.jpg',\n '1117525088.jpg',\n '1117527362.jpg',\n '1117542857.jpg',\n '1117772096.jpg',\n '1117878248.jpg',\n '1117879994.jpg',\n '1118130704.jpg',\n '1118276569.jpg',\n '1118497030.jpg',\n '1118637895.jpg',\n '1118643067.jpg',\n '1119555436.jpg',\n '1119607448.jpg',\n '1119608326.jpg',\n '111999583.jpg',\n '111999585.jpg',\n '111999587.jpg',\n '111999588.jpg',\n '1120144251.jpg',\n '1121278517.jpg',\n '11213996.jpg',\n '1122132670.jpg',\n '1122286847.jpg',\n '1123878399.jpg',\n '1124005923.jpg',\n '1124032789.jpg',\n '1124116427.jpg',\n '1124263281.jpg',\n '1124734012.jpg',\n '1124841098.jpg',\n '1125609465.jpg',\n '112584439.jpg',\n '112599313.jpg',\n '112602793.jpg',\n '1126344755.jpg',\n '1127167648.jpg',\n '1128010910.jpg',\n '1128108533.jpg',\n '1129241287.jpg',\n '1129286946.jpg',\n '112936682.jpg',\n '112937777.jpg',\n '112941431.jpg',\n '112942606.jpg',\n '112944361.jpg',\n '112945876.jpg',\n '112967569.jpg',\n '1129715025.jpg',\n '1129726637.jpg',\n '112996545.jpg',\n '1130060049.jpg',\n '1130126753.jpg',\n '1130407541.jpg',\n '113068882.jpg',\n '113071095.jpg',\n '1130771231.jpg',\n '1130803525.jpg',\n '1130854637.jpg',\n '1131174868.jpg',\n '1131338284.jpg',\n '11313980.jpg',\n '1131622204.jpg',\n '1131645902.jpg',\n '1131648810.jpg',\n '1131668206.jpg',\n '1131690523.jpg',\n '1131862116.jpg',\n '113287686.jpg',\n '113287687.jpg',\n '113460400.jpg',\n '113460507.jpg',\n '113460565.jpg',\n '113475647.jpg',\n '113475648.jpg',\n '113475650.jpg',\n '1134798481.jpg',\n '113539284.jpg',\n '113581900.jpg',\n '1135992768.jpg',\n '113683603.jpg',\n '113807539.jpg',\n '113807680.jpg',\n '113807720.jpg',\n '113807784.jpg',\n '113807974.jpg',\n '1138142509.jpg',\n '113841091.jpg',\n '1138955488.jpg',\n '1138984148.jpg',\n '1139082906.jpg',\n '1139598686.jpg',\n '1140006502.jpg',\n '1140395680.jpg',\n '1141148037.jpg',\n '1141674746.jpg',\n '1141699551.jpg',\n '1141748826.jpg',\n '114177444.jpg',\n '1141962112.jpg',\n '114289322.jpg',\n '114325853.jpg',\n '1143936441.jpg',\n '1143986823.jpg',\n '1144071878.jpg',\n '1145236242.jpg',\n '1148185470.jpg',\n '1148369652.jpg',\n '1150155911.jpg',\n '1150211597.jpg',\n '1150484049.jpg',\n '1150524175.jpg',\n '1151317134.jpg',\n '1151324292.jpg',\n '1151384850.jpg',\n '1151391790.jpg',\n '1151431264.jpg',\n '1151557065.jpg',\n '115156741.jpg',\n '115168260.jpg',\n '1151753578.jpg',\n '1151932531.jpg',\n '1152016044.jpg',\n '115219060.jpg',\n '1152311301.jpg',\n '1152355507.jpg',\n '1152368285.jpg',\n '1152438396.jpg',\n '1152588977.jpg',\n '1152695473.jpg',\n '1152737929.jpg',\n '1152738485.jpg',\n '1153054460.jpg',\n '1153146300.jpg',\n '1153195682.jpg',\n '1153308170.jpg',\n '1153308188.jpg',\n '1153337386.jpg',\n '1153357076.jpg',\n '1153408679.jpg',\n '1153523928.jpg',\n '1153545276.jpg',\n '1154254062.jpg',\n '11556521.jpg',\n '11559118.jpg',\n '11559156.jpg',\n '115621897.jpg',\n '1156434049.jpg',\n '115895486.jpg',\n '115912699.jpg',\n '115980605.jpg',\n '1160813683.jpg',\n '1160887628.jpg',\n '1161213323.jpg',\n '116194035.jpg',\n '1162330655.jpg',\n '1162516899.jpg',\n '1162529025.jpg',\n '1162550479.jpg',\n '1162552079.jpg',\n '1162552867.jpg',\n '1162623157.jpg',\n '1162631117.jpg',\n '116271935.jpg',\n '116302192.jpg',\n '116302408.jpg',\n '116302627.jpg',\n '1163342546.jpg',\n '1163447146.jpg',\n '1163455300.jpg',\n '1163954001.jpg',\n '1164407144.jpg',\n '1164418164.jpg',\n '1164425410.jpg',\n '116443849.jpg',\n '1164448315.jpg',\n '1164775803.jpg',\n '1164796353.jpg',\n '116487991.jpg',\n '116488756.jpg',\n '116489828.jpg',\n '116489951.jpg',\n '116490054.jpg',\n '116490183.jpg',\n '116490582.jpg',\n '116490865.jpg',\n '116491187.jpg',\n '116491270.jpg',\n '1165150393.jpg',\n '1165294152.jpg',\n '1165900214.jpg',\n '11661564.jpg',\n '11662656.jpg',\n '11662674.jpg',\n '1166575305.jpg',\n '1166577189.jpg',\n '1166581291.jpg',\n '1166581431.jpg',\n '116726937.jpg',\n '116729700.jpg',\n '116732100.jpg',\n '116732147.jpg',\n '1167431510.jpg',\n '1167435840.jpg',\n '1167438122.jpg',\n '116748573.jpg',\n '1169065337.jpg',\n '1169177793.jpg',\n '1169262469.jpg',\n '1169269017.jpg',\n '1169291683.jpg',\n '1169298319.jpg',\n '116940202.jpg',\n '116940275.jpg',\n '116940400.jpg',\n '116940943.jpg',\n '1169917752.jpg',\n '116994713.jpg',\n '1170027852.jpg',\n '1170121480.jpg',\n '1170130576.jpg',\n '1170133554.jpg',\n '1170145310.jpg',\n '1170181331.jpg',\n '1170257356.jpg',\n '1170964176.jpg',\n '1171267005.jpg',\n '1171272333.jpg',\n '117131427.jpg',\n '117131429.jpg',\n '117131430.jpg',\n '117133605.jpg',\n '1171367162.jpg',\n '1171369726.jpg',\n '1171376260.jpg',\n '117169925.jpg',\n '1172116874.jpg',\n '1172335504.jpg',\n '1172388449.jpg',\n '11724149.jpg',\n '1172421790.jpg',\n '11725981.jpg',\n '11726007.jpg',\n '117267806.jpg',\n '11727293.jpg',\n '11727332.jpg',\n '11727374.jpg',\n '117283428.jpg',\n '117286959.jpg',\n '1172914749.jpg',\n '1172982529.jpg',\n '1173096455.jpg',\n '1173424939.jpg',\n '11734602.jpg',\n '11735115.jpg',\n '11735219.jpg',\n '1173580558.jpg',\n '11735860.jpg',\n '11736044.jpg',\n '11736079.jpg',\n '11736197.jpg',\n '11736297.jpg',\n '11736315.jpg',\n '11736354.jpg',\n '1173820761.jpg',\n '1173941281.jpg',\n '1173945609.jpg',\n '1173948147.jpg',\n '1173966501.jpg',\n '1173987153.jpg',\n '1174003543.jpg',\n '1174024321.jpg',\n '1174094227.jpg',\n '1174122357.jpg',\n '1174131687.jpg',\n '1174611083.jpg',\n '1174815376.jpg',\n '1174821894.jpg',\n '1174851616.jpg',\n '1174873678.jpg',\n '1174961726.jpg',\n '1175040936.jpg',\n '1175119028.jpg',\n '1175192748.jpg',\n '117635716.jpg',\n '117636966.jpg',\n '117640639.jpg',\n '117643218.jpg',\n '117643940.jpg',\n '117644662.jpg',\n '117645218.jpg',\n '117645222.jpg',\n '117645223.jpg',\n '117647117.jpg',\n '117716938.jpg',\n '117807314.jpg',\n '1178544074.jpg',\n '117855938.jpg',\n '11786961.jpg',\n '117876571.jpg',\n '117938775.jpg',\n '1180108271.jpg',\n '11801995.jpg',\n '11802070.jpg',\n '11802387.jpg',\n '118052875.jpg',\n '118065500.jpg',\n '118065542.jpg',\n '118073346.jpg',\n '118090374.jpg',\n '118090376.jpg',\n '118092878.jpg',\n '118092879.jpg',\n '1180965626.jpg',\n '1180966272.jpg',\n '1180975962.jpg',\n '1180976486.jpg',\n '118162580.jpg',\n '118170329.jpg',\n '118178862.jpg',\n '118180027.jpg',\n '1182320768.jpg',\n '1182482397.jpg',\n '1182485667.jpg',\n '1182532836.jpg',\n '11830024.jpg',\n '1183141183.jpg',\n '1183189059.jpg',\n '1183198653.jpg',\n '1183301621.jpg',\n '1183307141.jpg',\n '1183342876.jpg',\n '1183927418.jpg',\n '1183986529.jpg',\n '1183987401.jpg',\n '1184040140.jpg',\n '118404096.jpg',\n '1184074579.jpg',\n '1184075917.jpg',\n '1184076627.jpg',\n '1184092935.jpg',\n '1184119615.jpg',\n '1184157123.jpg',\n '1184160163.jpg',\n '1184162698.jpg',\n '1184173785.jpg',\n '118441396.jpg',\n '1184718099.jpg',\n '1184812667.jpg',\n '1184845220.jpg',\n '1184941720.jpg',\n '1184943954.jpg',\n '1184948404.jpg',\n '1184966158.jpg',\n '1184967384.jpg',\n '1184974808.jpg',\n '1184987878.jpg',\n '1185001966.jpg',\n '1185037886.jpg',\n '1185158041.jpg',\n '11855542.jpg',\n '1185962484.jpg',\n '1185971952.jpg',\n '1185978806.jpg',\n '1188281786.jpg',\n '1189465369.jpg',\n '1189677962.jpg',\n '118980500.jpg',\n '118983099.jpg',\n '118987039.jpg',\n '118987737.jpg',\n '118992911.jpg',\n '1190341698.jpg',\n '1190637645.jpg',\n '1190648839.jpg',\n '1190853631.jpg',\n '1190969205.jpg',\n '119121498.jpg',\n '1191326691.jpg',\n '1191348139.jpg',\n '1191377549.jpg',\n '1191378951.jpg',\n '1191381121.jpg',\n '1191381259.jpg',\n '1191404295.jpg',\n '1191424621.jpg',\n '1191448875.jpg',\n '1191451909.jpg',\n '1191465691.jpg',\n '1191471361.jpg',\n '1191535910.jpg',\n '1191688410.jpg',\n '1191745318.jpg',\n '1191750148.jpg',\n '1191807652.jpg',\n '1192008807.jpg',\n '1192008937.jpg',\n '1192156455.jpg',\n '1192209786.jpg',\n '11922320.jpg',\n '11922322.jpg',\n '1192254930.jpg',\n '1192264574.jpg',\n '1192270926.jpg',\n '1192292030.jpg',\n '1192336381.jpg',\n '1192338280.jpg',\n '1192356953.jpg',\n '1192364373.jpg',\n '1192376963.jpg',\n '1192412508.jpg',\n '1192416310.jpg',\n '119252926.jpg',\n '1192865551.jpg',\n '1192877814.jpg',\n '1192900761.jpg',\n '1192903011.jpg',\n '1192906891.jpg',\n '1192910955.jpg',\n '119291648.jpg',\n '1192987658.jpg',\n '1193005234.jpg',\n '1193091100.jpg',\n '119324240.jpg',\n '1193309666.jpg',\n '1193338584.jpg',\n '119339910.jpg',\n '119339999.jpg',\n '119343900.jpg',\n '1193613075.jpg',\n '1193729117.jpg',\n '1193742203.jpg',\n '1193749981.jpg',\n '119375693.jpg',\n '1193764162.jpg',\n '119382878.jpg',\n '1193856251.jpg',\n '119389628.jpg',\n '1193989035.jpg',\n '119402813.jpg',\n '1194038435.jpg',\n '1194096860.jpg',\n '1194117830.jpg',\n '1194341941.jpg',\n '1194349655.jpg',\n '1194421969.jpg',\n '1194424167.jpg',\n '1194426833.jpg',\n '1194628390.jpg',\n '1194724574.jpg',\n '1194734238.jpg',\n '1194766048.jpg',\n '1194836210.jpg',\n '1195215022.jpg',\n '1195249397.jpg',\n '1195296768.jpg',\n '1195302526.jpg',\n '1195541313.jpg',\n '1195587261.jpg',\n '1195647097.jpg',\n '1195650853.jpg',\n '1195666391.jpg',\n '1195674955.jpg',\n '1195757887.jpg',\n '1195948647.jpg',\n '1195995383.jpg',\n '1196113993.jpg',\n '1196365624.jpg',\n '1196510618.jpg',\n '1196525626.jpg',\n '1196556916.jpg',\n '119656076.jpg',\n '1196561754.jpg',\n '1196566292.jpg',\n '1196570424.jpg',\n '1196645708.jpg',\n '1196682898.jpg',\n '1196703867.jpg',\n '1196743566.jpg',\n '1196810824.jpg',\n '1196833108.jpg',\n '1196871964.jpg',\n '1196991040.jpg',\n '1197707050.jpg',\n '1197711363.jpg',\n '119812323.jpg',\n '119814180.jpg',\n '119817130.jpg',\n '119829783.jpg',\n '119829855.jpg',\n '119829873.jpg',\n '119890312.jpg',\n '119902933.jpg',\n '119903009.jpg',\n '1199394937.jpg',\n '1199419516.jpg',\n '11996282.jpg',\n '11997633.jpg',\n '11999851.jpg',\n '12000430.jpg',\n '120009112.jpg',\n '12001216.jpg',\n '1200190815.jpg',\n '1200210097.jpg',\n '1200238001.jpg',\n '120024191.jpg',\n '12002539.jpg',\n '1200281989.jpg',\n '12003087.jpg',\n '12003359.jpg',\n '12003890.jpg',\n '1200546899.jpg',\n '1200550139.jpg',\n '1200582233.jpg',\n '1200592131.jpg',\n '1200595447.jpg',\n '1200712091.jpg',\n '1200720019.jpg',\n '1200741223.jpg',\n '1200947500.jpg',\n '1200955015.jpg',\n '1200998941.jpg',\n '1201068588.jpg',\n '1201071810.jpg',\n '1201095649.jpg',\n '1201102426.jpg',\n '120111967.jpg',\n '120111968.jpg',\n '1201122935.jpg',\n '1201132037.jpg',\n '1201162540.jpg',\n '1201174121.jpg',\n '120117693.jpg',\n '1201355896.jpg',\n '1201359298.jpg',\n '1201398794.jpg',\n '1201420194.jpg',\n '1201423686.jpg',\n '1201493408.jpg',\n '1201603274.jpg',\n '1201610310.jpg',\n '1201618030.jpg',\n '120173793.jpg',\n '120186176.jpg',\n '1202046834.jpg',\n '1202056438.jpg',\n '1202068103.jpg',\n '1202071056.jpg',\n '1202073109.jpg',\n '1202113553.jpg',\n '1202114663.jpg',\n '1202244865.jpg',\n '1202246549.jpg',\n '1202248715.jpg',\n '1202250622.jpg',\n '1202251919.jpg',\n '120239101.jpg',\n '1202554596.jpg',\n '1202653719.jpg',\n '1202678807.jpg',\n '1202939066.jpg',\n '1202969732.jpg',\n '1202990488.jpg',\n '1203017741.jpg',\n '1203099340.jpg',\n '1203104040.jpg',\n '1203112732.jpg',\n '1203115724.jpg',\n '1203116948.jpg',\n '1203510845.jpg',\n '1203518410.jpg',\n '1203526903.jpg',\n '1203869087.jpg',\n '1204563197.jpg',\n '1204733982.jpg',\n '1205480253.jpg',\n '1205865648.jpg',\n '1205871521.jpg',\n '1206509112.jpg',\n '1206707335.jpg',\n '1206741408.jpg',\n '1207018417.jpg',\n '1207052084.jpg',\n '1207505603.jpg',\n '1207506375.jpg',\n '1207631271.jpg',\n '1207640729.jpg',\n '1207846757.jpg',\n '1207848205.jpg',\n '1207868039.jpg',\n '120836065.jpg',\n '1208426427.jpg',\n '1208428170.jpg',\n '120844852.jpg',\n '1208545629.jpg',\n '1208550517.jpg',\n '1208725080.jpg',\n '120879986.jpg',\n '1208911554.jpg',\n '1208970387.jpg',\n '1208991167.jpg',\n '1209213094.jpg',\n '1209256270.jpg',\n '1209291554.jpg',\n '120931343.jpg',\n '1209401854.jpg',\n '1209412916.jpg',\n '120985782.jpg',\n '1209898694.jpg',\n '1210084603.jpg',\n '121010157.jpg',\n '121010898.jpg',\n '121011751.jpg',\n '121012962.jpg',\n '121014235.jpg',\n '121015907.jpg',\n '121029117.jpg',\n '121034110.jpg',\n '121037242.jpg',\n '121038134.jpg',\n '121046614.jpg',\n '121047513.jpg',\n '1210649425.jpg',\n '1210651631.jpg',\n '1210891963.jpg',\n '1210932317.jpg',\n '121114022.jpg',\n '121115837.jpg',\n '1211861714.jpg',\n '121248336.jpg',\n '1212883479.jpg',\n '1212886335.jpg',\n '1213328425.jpg',\n '1213367195.jpg',\n '1213426301.jpg',\n '121345782.jpg',\n '121345859.jpg',\n '121345919.jpg',\n '1213743938.jpg',\n '1213799186.jpg',\n '121415432.jpg',\n '1214200398.jpg',\n '1214211482.jpg',\n '1214234199.jpg',\n '1214239242.jpg',\n '121424023.jpg',\n '121424689.jpg',\n '121434852.jpg',\n '121435089.jpg',\n '1214612854.jpg',\n '12150555.jpg',\n '12150629.jpg',\n '1215375629.jpg',\n '121543139.jpg',\n '1215744999.jpg',\n '1215873609.jpg',\n '121588512.jpg',\n '1215907060.jpg',\n '1216078211.jpg',\n '1216620044.jpg',\n '1216832891.jpg',\n '1216834005.jpg',\n '1216848517.jpg',\n '1216860495.jpg',\n '1216861363.jpg',\n '1216915432.jpg',\n '121698415.jpg',\n '1217209017.jpg',\n ...]"},"transient":{},"execution_count":11}],"source":"list(map(lambda x:x.split('/')[-1],test_generator.filenames))","execution_count":11},{"metadata":{"id":"53046A0B82854A758A78463CC89FA6EA","notebookId":"5f8a59a1bfe3ac0015e8dfb2","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"1    30755\n2    24476\n0    17547\ndtype: int64"},"transient":{},"execution_count":28}],"source":"pd.DataFrame(np.argmax(pred, axis=-1)).value_counts()","execution_count":28},{"metadata":{"id":"4DAD2D484CCA46498989B66A17DFA7F9","notebookId":"5f8a59a1bfe3ac0015e8dfb2","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"              1         2         0\n0      0.526464  0.077025  0.396511\n1      0.008898  0.040022  0.951080\n2      0.174207  0.084389  0.741404\n3      0.231672  0.071458  0.696870\n4      0.697254  0.302373  0.000373\n...         ...       ...       ...\n72773  0.000255  0.999638  0.000107\n72774  0.377342  0.576091  0.046567\n72775  0.371540  0.370029  0.258431\n72776  0.658033  0.318002  0.023965\n72777  0.063050  0.931597  0.005353\n\n[72778 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>1</th>\n      <th>2</th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.526464</td>\n      <td>0.077025</td>\n      <td>0.396511</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.008898</td>\n      <td>0.040022</td>\n      <td>0.951080</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.174207</td>\n      <td>0.084389</td>\n      <td>0.741404</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.231672</td>\n      <td>0.071458</td>\n      <td>0.696870</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.697254</td>\n      <td>0.302373</td>\n      <td>0.000373</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>72773</th>\n      <td>0.000255</td>\n      <td>0.999638</td>\n      <td>0.000107</td>\n    </tr>\n    <tr>\n      <th>72774</th>\n      <td>0.377342</td>\n      <td>0.576091</td>\n      <td>0.046567</td>\n    </tr>\n    <tr>\n      <th>72775</th>\n      <td>0.371540</td>\n      <td>0.370029</td>\n      <td>0.258431</td>\n    </tr>\n    <tr>\n      <th>72776</th>\n      <td>0.658033</td>\n      <td>0.318002</td>\n      <td>0.023965</td>\n    </tr>\n    <tr>\n      <th>72777</th>\n      <td>0.063050</td>\n      <td>0.931597</td>\n      <td>0.005353</td>\n    </tr>\n  </tbody>\n</table>\n<p>72778 rows × 3 columns</p>\n</div>"},"transient":{},"execution_count":39}],"source":"import pandas as pd\nresult = pd.DataFrame(pred)\nresult.columns = [1, 2, 0]\nresult.to_csv(\"/home/kesci/work/incep_819.csv\", index=False)\nresult","execution_count":39},{"metadata":{"id":"14703488F91E4009AC6C2D7D5C2C5B69","notebookId":"5f8a59a1bfe3ac0015e8dfb2","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"                    id weather\n0        100017842.jpg       1\n1        100057293.jpg       0\n2       1000599894.jpg       0\n3       1000600110.jpg       0\n4       1000974891.jpg       1\n...                ...     ...\n72773  99997209972.jpg       2\n72774  99997809978.jpg       2\n72775   9999800998.jpg       1\n72776  99998609986.jpg       1\n72777  99999909999.jpg       2\n\n[72778 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>weather</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>100017842.jpg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>100057293.jpg</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1000599894.jpg</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1000600110.jpg</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1000974891.jpg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>72773</th>\n      <td>99997209972.jpg</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>72774</th>\n      <td>99997809978.jpg</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>72775</th>\n      <td>9999800998.jpg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>72776</th>\n      <td>99998609986.jpg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>72777</th>\n      <td>99999909999.jpg</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>72778 rows × 2 columns</p>\n</div>"},"transient":{},"execution_count":37}],"source":"submit","execution_count":37},{"metadata":{"id":"F1851D821667443285184B45FFFAFBAB","notebookId":"5f8a59a1bfe3ac0015e8dfb2","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"submit=pd.DataFrame()\nsubmit['id']=list(map(lambda x:x.split('/')[-1],test_generator.filenames))\nsubmit['weather']=np.argmax(pred, axis=-1)\nsubmit.loc[submit.weather==2,'weather']='sunny'\nsubmit.loc[submit.weather==1,'weather']='others'\nsubmit.loc[submit.weather==0,'weather']='cloudy'\n\nsubmit.loc[submit.weather=='sunny','weather']=0\nsubmit.loc[submit.weather=='cloudy','weather']=1\nsubmit.loc[submit.weather=='others','weather']=2","execution_count":19},{"metadata":{"id":"FCB8685895874323899900DE87C4872B","notebookId":"5f8a59a1bfe3ac0015e8dfb2","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"2    30755\n0    24476\n1    17547\nName: weather, dtype: int64"},"transient":{},"execution_count":22}],"source":"submit.weather.value_counts()","execution_count":22},{"metadata":{"id":"C9498EB1BCBA42C1A8E86A1E697ACEB8","notebookId":"5f8a59a1bfe3ac0015e8dfb2","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"submit.to_csv('/home/kesci/work/incep_submit.csv',index=False)","execution_count":23},{"metadata":{"id":"AC3956E689D64A3280B501D8C87BD0F1","notebookId":"5f8a59a1bfe3ac0015e8dfb2","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"                    id  weather\n0        100017842.jpg        1\n1        100057293.jpg        0\n2       1000599894.jpg        0\n3       1000600110.jpg        0\n4       1000974891.jpg        1\n...                ...      ...\n72773  99997209972.jpg        2\n72774  99997809978.jpg        2\n72775   9999800998.jpg        1\n72776  99998609986.jpg        1\n72777  99999909999.jpg        2\n\n[72778 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>weather</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>100017842.jpg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>100057293.jpg</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1000599894.jpg</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1000600110.jpg</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1000974891.jpg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>72773</th>\n      <td>99997209972.jpg</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>72774</th>\n      <td>99997809978.jpg</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>72775</th>\n      <td>9999800998.jpg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>72776</th>\n      <td>99998609986.jpg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>72777</th>\n      <td>99999909999.jpg</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>72778 rows × 2 columns</p>\n</div>"},"transient":{},"execution_count":24}],"source":"pd.read_csv('/home/kesci/work/incep_submit.csv')","execution_count":24},{"metadata":{"id":"A03A79DACB074168874B7B02DB241BF8","notebookId":"5f8a59a1bfe3ac0015e8dfb2","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n94773248/94765736 [==============================] - 38s 0us/step\nTrain on 140466 samples, validate on 35117 samples\nEpoch 1/30\n140466/140466 [==============================] - 531s 4ms/sample - loss: 0.9414 - accuracy: 0.5920 - val_loss: 0.9717 - val_accuracy: 0.5640\nEpoch 2/30\n140466/140466 [==============================] - 222s 2ms/sample - loss: 0.9336 - accuracy: 0.6028 - val_loss: 0.9134 - val_accuracy: 0.6284\nEpoch 3/30\n140466/140466 [==============================] - 219s 2ms/sample - loss: 0.9147 - accuracy: 0.6245 - val_loss: 1.0589 - val_accuracy: 0.4534\nEpoch 4/30\n140466/140466 [==============================] - 223s 2ms/sample - loss: 0.9090 - accuracy: 0.6331 - val_loss: 0.9100 - val_accuracy: 0.6297\nEpoch 5/30\n140466/140466 [==============================] - 220s 2ms/sample - loss: 0.9071 - accuracy: 0.6339 - val_loss: 0.9168 - val_accuracy: 0.6203\nEpoch 6/30\n140466/140466 [==============================] - 223s 2ms/sample - loss: 0.9054 - accuracy: 0.6353 - val_loss: 0.9085 - val_accuracy: 0.6341\nEpoch 7/30\n140466/140466 [==============================] - 220s 2ms/sample - loss: 0.9034 - accuracy: 0.6382 - val_loss: 0.9420 - val_accuracy: 0.5992\nEpoch 8/30\n140466/140466 [==============================] - 220s 2ms/sample - loss: 0.9014 - accuracy: 0.6396 - val_loss: 0.9535 - val_accuracy: 0.5906\nEpoch 9/30\n140466/140466 [==============================] - 220s 2ms/sample - loss: 0.9021 - accuracy: 0.6392 - val_loss: 1.0352 - val_accuracy: 0.5122\nEpoch 10/30\n 29248/140466 [=====>........................] - ETA: 2:48 - loss: 0.9091 - accuracy: 0.6321","name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-101-17223a1086c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m model.fit(x_tra, y_tra,\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/engine/training_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_select_training_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m     return func.fit(\n\u001b[0m\u001b[1;32m    791\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    647\u001b[0m       \u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_sample_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m     return fit_loop(\n\u001b[0m\u001b[1;32m    650\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3822\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_arrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_symbols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3824\u001b[0;31m     fetched = self._callable_fn(*array_vals,\n\u001b[0m\u001b[1;32m   3825\u001b[0m                                 run_metadata=self.run_metadata)\n\u001b[1;32m   3826\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1468\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1469\u001b[0m         \u001b[0mrun_metadata_ptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_NewBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1470\u001b[0;31m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0m\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1472\u001b[0m                                                run_metadata_ptr)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":"# model=CNN_model()\nmodel=Model()\nEarlyStop=EarlyStopping(monitor='val_accuracy',\n                        patience=8,verbose=1, mode='auto')\n#减小学习率\nReduce=ReduceLROnPlateau(monitor='val_accuracy',\n                         factor=0.2,\n                         patience=8,\n                         verbose=1,\n                         mode='auto',\n                        #  min_delta=0.0001,\n                         cooldown=0,\n                         min_lr=0\n                         )\ncheckpoint = ModelCheckpoint(f'/home/kesci/work/cnn_model/mobeilnet_v2.h5',\n                            monitor='val_accuracy',\n                            verbose=0,\n                            mode='auto',\n                            save_best_only=True\n)\n\n\nmodel.fit(x_tra, y_tra,\n        validation_data=(x_val,y_val),\n        validation_freq=1,\n        callbacks=[EarlyStop,Reduce,checkpoint],\n        batch_size=64,\n        epochs=30)","execution_count":101},{"metadata":{"id":"61DEE72AC88E411198F947FF20992C0B","notebookId":"5f8a59a1bfe3ac0015e8dfb2","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","outputs":[],"source":"from sklearn.metrics import f1_score\nscore=f1_score(y_val_df.values, val_pred_df['label1'].values, average='macro')\nprint(\"F1_Score:\",score)","execution_count":null},{"metadata":{"id":"C617B07010394AF986BDCB8DF038B008","notebookId":"5f8a59a1bfe3ac0015e8dfb2","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","outputs":[],"source":"","execution_count":null},{"metadata":{"id":"DD3D12048CE84AB585D7C9A2D11E8331","notebookId":"5f8a59a1bfe3ac0015e8dfb2","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","outputs":[],"source":"","execution_count":null},{"metadata":{"id":"FA2EA91814E6455581D14A6ECF4630C3","notebookId":"5f8a59a1bfe3ac0015e8dfb2","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","outputs":[],"source":"","execution_count":null},{"metadata":{"id":"C73590A57EE041BD88A1A3AA77FE8DE7","notebookId":"5f8a59a1bfe3ac0015e8dfb2","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","outputs":[],"source":"","execution_count":null},{"metadata":{"id":"73C65199AC084E6A863E04610C0DFFE2","notebookId":"5f8a59a1bfe3ac0015e8dfb2","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","outputs":[],"source":"","execution_count":null},{"metadata":{"id":"FDCB63EAF814402389B4070E3CE5014A","notebookId":"5f8a59a1bfe3ac0015e8dfb2","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","outputs":[],"source":"","execution_count":null},{"metadata":{"id":"FB3B73B329CE47FABA73DE4D1B28BF79","notebookId":"5f8a59a1bfe3ac0015e8dfb2","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":" index=label[label['label2']<2].index\n x_tra2, x_val2, y_tra2, y_val2 = train_test_split(train[index,],label.loc[label['label2']<2,'label2'], test_size=0.2,shuffle=True,random_state=3090)","execution_count":74},{"metadata":{"id":"864D5BDAF9D4443EA4E2A994AE6AEE28","notebookId":"5f8a59a1bfe3ac0015e8dfb2","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":true},"cell_type":"code","outputs":[{"output_type":"stream","text":"Train on 80656 samples, validate on 20164 samples\nEpoch 1/30\n80656/80656 [==============================] - 13s 157us/sample - loss: 0.5594 - accuracy: 0.7375 - val_loss: 0.5474 - val_accuracy: 0.7580\nEpoch 2/30\n80656/80656 [==============================] - 12s 151us/sample - loss: 0.5412 - accuracy: 0.7570 - val_loss: 0.5244 - val_accuracy: 0.7754\nEpoch 3/30\n80656/80656 [==============================] - 12s 151us/sample - loss: 0.5370 - accuracy: 0.7617 - val_loss: 0.5228 - val_accuracy: 0.7771\nEpoch 4/30\n80656/80656 [==============================] - 12s 151us/sample - loss: 0.5301 - accuracy: 0.7692 - val_loss: 0.5152 - val_accuracy: 0.7817\nEpoch 5/30\n80656/80656 [==============================] - 12s 151us/sample - loss: 0.5269 - accuracy: 0.7713 - val_loss: 0.5251 - val_accuracy: 0.7714\nEpoch 6/30\n80656/80656 [==============================] - 12s 151us/sample - loss: 0.5233 - accuracy: 0.7768 - val_loss: 0.5114 - val_accuracy: 0.7873\nEpoch 7/30\n80656/80656 [==============================] - 12s 152us/sample - loss: 0.5195 - accuracy: 0.7808 - val_loss: 0.5088 - val_accuracy: 0.7910\nEpoch 8/30\n80656/80656 [==============================] - 12s 151us/sample - loss: 0.5160 - accuracy: 0.7835 - val_loss: 0.5056 - val_accuracy: 0.7947\nEpoch 9/30\n80656/80656 [==============================] - 12s 151us/sample - loss: 0.5139 - accuracy: 0.7864 - val_loss: 0.5067 - val_accuracy: 0.7942\nEpoch 10/30\n80656/80656 [==============================] - 12s 151us/sample - loss: 0.5112 - accuracy: 0.7898 - val_loss: 0.5027 - val_accuracy: 0.7975\nEpoch 11/30\n80656/80656 [==============================] - 12s 151us/sample - loss: 0.5092 - accuracy: 0.7911 - val_loss: 0.5014 - val_accuracy: 0.7977\nEpoch 12/30\n80656/80656 [==============================] - 12s 151us/sample - loss: 0.5081 - accuracy: 0.7930 - val_loss: 0.5010 - val_accuracy: 0.8011\nEpoch 13/30\n80656/80656 [==============================] - 12s 151us/sample - loss: 0.5060 - accuracy: 0.7952 - val_loss: 0.5181 - val_accuracy: 0.7793\nEpoch 14/30\n80656/80656 [==============================] - 12s 151us/sample - loss: 0.5054 - accuracy: 0.7953 - val_loss: 0.5004 - val_accuracy: 0.7996\nEpoch 15/30\n80656/80656 [==============================] - 12s 151us/sample - loss: 0.5030 - accuracy: 0.7990 - val_loss: 0.5021 - val_accuracy: 0.7999\nEpoch 16/30\n80656/80656 [==============================] - 12s 151us/sample - loss: 0.5011 - accuracy: 0.8021 - val_loss: 0.4994 - val_accuracy: 0.8009\nEpoch 17/30\n80656/80656 [==============================] - 12s 151us/sample - loss: 0.4994 - accuracy: 0.8033 - val_loss: 0.4980 - val_accuracy: 0.8037\nEpoch 18/30\n80656/80656 [==============================] - 12s 151us/sample - loss: 0.4978 - accuracy: 0.8047 - val_loss: 0.4987 - val_accuracy: 0.8010\nEpoch 19/30\n80656/80656 [==============================] - 12s 151us/sample - loss: 0.4972 - accuracy: 0.8061 - val_loss: 0.5071 - val_accuracy: 0.7948\nEpoch 20/30\n80656/80656 [==============================] - 12s 150us/sample - loss: 0.4955 - accuracy: 0.8080 - val_loss: 0.4998 - val_accuracy: 0.8019\nEpoch 21/30\n80656/80656 [==============================] - 12s 151us/sample - loss: 0.4958 - accuracy: 0.8086 - val_loss: 0.4998 - val_accuracy: 0.8018\nEpoch 22/30\n80656/80656 [==============================] - 12s 150us/sample - loss: 0.4935 - accuracy: 0.8105 - val_loss: 0.5037 - val_accuracy: 0.7982\nEpoch 23/30\n80656/80656 [==============================] - 12s 151us/sample - loss: 0.4925 - accuracy: 0.8123 - val_loss: 0.5101 - val_accuracy: 0.7908\nEpoch 24/30\n80656/80656 [==============================] - 12s 151us/sample - loss: 0.4919 - accuracy: 0.8128 - val_loss: 0.4991 - val_accuracy: 0.8030\nEpoch 25/30\n80656/80656 [==============================] - ETA: 0s - loss: 0.4911 - accuracy: 0.8122\nEpoch 00025: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n80656/80656 [==============================] - 12s 152us/sample - loss: 0.4911 - accuracy: 0.8122 - val_loss: 0.5096 - val_accuracy: 0.7919\nEpoch 00025: early stopping\n","name":"stdout"},{"output_type":"execute_result","metadata":{},"data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f20a8047f70>"},"transient":{},"execution_count":75}],"source":"model1=CNN_model()\nmodel1.fit(x_tra2, y_tra2,\n        validation_data=(x_val2,y_val2),\n        validation_freq=1,\n        callbacks=[EarlyStop,Reduce,checkpoint],\n        batch_size=128,\n        epochs=30)","execution_count":75},{"metadata":{"id":"8F0A09A0E30B4439B8904BD2B8E18E12","notebookId":"5f8a59a1bfe3ac0015e8dfb2","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"array([0, 1, 0, ..., 0, 1, 0])"},"transient":{},"execution_count":84}],"source":"val_pred=np.argmax(model.predict(x_val), axis=-1)\nval_pred","execution_count":84},{"metadata":{"id":"CE10995E374A4DE3BBB47226BE6FB622","notebookId":"5f8a59a1bfe3ac0015e8dfb2","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"       label  label1\n0          0       0\n1          1       2\n2          0       0\n3          0       1\n4          0       1\n...      ...     ...\n35112      0       0\n35113      0       0\n35114      0       0\n35115      1       2\n35116      0       0\n\n[35117 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>label1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>35112</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>35113</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>35114</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>35115</th>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>35116</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>35117 rows × 2 columns</p>\n</div>"},"transient":{},"execution_count":85}],"source":"val_pred_df=pd.DataFrame(val_pred,columns=['label'])\nval_pred_df['label1']=2\nindex1=val_pred_df[val_pred_df['label']==0].index\nval_pred_df.loc[index1,'label1']=np.argmax(model1.predict(x_val[index1,]), axis=-1)\nval_pred_df","execution_count":85},{"metadata":{"id":"69E82CCB12184C9D8AED8B3C2101F13B","notebookId":"5f8a59a1bfe3ac0015e8dfb2","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"33260     0\n1687      1\n98804     0\n41140     0\n122824    0\n         ..\n61203     1\n14626     1\n35635     1\n94678     1\n29471     0\nName: label1, Length: 35117, dtype: int64"},"transient":{},"execution_count":86}],"source":"y_val","execution_count":86},{"metadata":{"id":"7CAABC94D0284DAB8EE4C61561867EBE","notebookId":"5f8a59a1bfe3ac0015e8dfb2","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"33260     0\n1687      2\n98804     0\n41140     1\n122824    1\n         ..\n61203     2\n14626     2\n35635     2\n94678     2\n29471     1\nName: label2, Length: 35117, dtype: int64"},"transient":{},"execution_count":87}],"source":"y_tra_df, y_val_df = train_test_split(label['label2'], test_size=0.2,shuffle=True,random_state=3090)\ny_val_df","execution_count":87},{"metadata":{"id":"CDA8A3BCFC2A4C338BC620B393363A2C","notebookId":"5f8a59a1bfe3ac0015e8dfb2","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"F1_Score: 0.6584370393697\n","name":"stdout"}],"source":"from sklearn.metrics import f1_score\nscore=f1_score(y_val_df.values, val_pred_df['label1'].values, average='macro')\nprint(\"F1_Score:\",score)","execution_count":88},{"metadata":{"id":"0665A22066CA482A8C1618BF9A9642B4","notebookId":"5f8a59a1bfe3ac0015e8dfb2","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"F1_Score: 0.66626642137718\n","name":"stdout"}],"source":"from sklearn.metrics import f1_score\nval_pred=model.predict_classes(x_val)\nscore=f1_score(y_val, val_pred, average='macro')\nprint(\"F1_Score:\",score)\n\n# test_loss, test_acc = model.evaluate(x_val,  y_val, verbose=2)\n# test_loss,test_acc","execution_count":12},{"metadata":{"id":"A93528B7A4584C099EB29C022A9AF515","notebookId":"5f8a59a1bfe3ac0015e8dfb2","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"array([2, 2, 2, ..., 1, 1, 1])"},"transient":{},"execution_count":12}],"source":"pred=model.predict_classes(test)\npred","execution_count":12},{"metadata":{"id":"AA4CA20BD89E4A3984C263DEF132380B","notebookId":"5f8a59a1bfe3ac0015e8dfb2","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"array(['sunny', 'sunny', 'sunny', ..., 'others', 'others', 'others'],\n      dtype=object)"},"transient":{},"execution_count":36}],"source":"le.inverse_transform(pred)","execution_count":36},{"metadata":{"id":"8F5624D82582418C83FC1C5AFD9D8926","notebookId":"5f8a59a1bfe3ac0015e8dfb2","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"2020-10-25 13:35:23 URL:https://cdn.kesci.com/submit_tool/v4/kesci_submit [7357446/7357446] -> \"kesci_submit\" [1]\r\n","name":"stdout"}],"source":"# !wget -nv -O kesci_submit https://cdn.kesci.com/submit_tool/v4/kesci_submit&&chmod +x kesci_submit","execution_count":17},{"metadata":{"id":"2A82BE7F6EE045ECBA1CEE403C06613B","notebookId":"5f8a59a1bfe3ac0015e8dfb2","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"Kesci Submit Tool 4.0.0\n\n> 已验证Token\n> 提交文件 /home/kesci/work/incep_submit.csv (1204.74 KiB), Target Qiniu\n> 已上传 100 %\n> 文件已上传        \n> 服务器响应: 200 提交成功，请等待评审完成\n> 提交完成\n","name":"stdout"}],"source":"# !./kesci_submit -token 7a503d402d41caa3 -file /home/kesci/work/incep_submit.csv","execution_count":25},{"metadata":{"id":"A484FCD1AC8645348464025D4BF89B4B","notebookId":"5f8a59a1bfe3ac0015e8dfb2","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","outputs":[],"source":"","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python","nbconvert_exporter":"python","file_extension":".py","version":"3.5.2","pygments_lexer":"ipython3"}},"nbformat":4,"nbformat_minor":0}